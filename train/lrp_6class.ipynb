{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from baselines.ViT.ViT_LRP_copy import vit_base_patch16_224 as vit_LRP\n",
    "from baselines.ViT.ViT_explanation_generator import LRP\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, vit_data,emotion,gambling):\n",
    "        self.emotion=[os.path.join(emotion,str(item)+'.mat') for item in vit_data]\n",
    "        self.gambling=[os.path.join(gambling,str(item)+'.mat') for item in vit_data]\n",
    "        self.data=self.emotion+self.gambling\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        image=self.data[idx]\n",
    "        image=h5py.File(image,'r')\n",
    "        image = np.array(image['fc_matrix'])\n",
    "        image=torch.from_numpy(image).float()\n",
    "        if self.data[idx] in self.emotion:\n",
    "            label=torch.tensor(0)\n",
    "        elif self.data[idx] in self.gambling:\n",
    "            label=torch.tensor(1)\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualization(original_image, class_index=None):\n",
    "        transformer_attribution = attribution_generator.generate_LRP(original_image.unsqueeze(0).to(device), method=\"transformer_attribution_conn\", index=class_index).detach().cpu()\n",
    "        # transformer_attribution = ((transformer_attribution - transformer_attribution.min()) / (transformer_attribution.max() - transformer_attribution.min()))\n",
    "        transformer_attribution_edge = transformer_attribution.reshape(156,156)[1:,1:]\n",
    "        transformer_attribution_node = transformer_attribution.reshape(156,156)[0,1:]\n",
    "        diag = torch.diag(transformer_attribution_edge)\n",
    "        a_diag = torch.diag_embed(diag)\n",
    "        transformer_attribution_edge = transformer_attribution_edge - a_diag\n",
    "        # transformer_attribution_edge = ((transformer_attribution_edge - transformer_attribution_edge.min()) / (transformer_attribution_edge.max() - transformer_attribution_edge.min()))\n",
    "        # transformer_attribution_node = ((transformer_attribution_node - transformer_attribution_node.min()) / (transformer_attribution_node.max() - transformer_attribution_node.min()))\n",
    "        return transformer_attribution_edge,transformer_attribution_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start percent divide:1998 0.2\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n"
     ]
    }
   ],
   "source": [
    "model = vit_LRP(pretrained=False,num_classes=2,in_chans=1)\n",
    "model.patch_embed=torch.nn.Linear(155,model.pos_embed.shape[2])\n",
    "model.pos_embed=torch.nn.Parameter(torch.zeros(1, 155+1, model.pos_embed.shape[2]))\n",
    "CLS2IDX =  ['emotion','gambling','language','motor','relational','social','wm']\n",
    "data = np.arange(1,1008)\n",
    "for random_state_num in range(1998,2004):\n",
    "    kf=KFold(n_splits=5,shuffle=True,random_state=random_state_num)\n",
    "    percent_value = [0.15,0.2,0.25,0.3]\n",
    "    for percent in range(1,2):\n",
    "        print('start percent divide:{} {}'.format(random_state_num,percent_value[percent]))\n",
    "        for k,(train_index, test_index) in list(enumerate(kf.split(data))):\n",
    "            emotion=\"/media/D/zephyr/functional_connectivity/HCP/s1200/percent_{}/EMOTION\".format(percent_value[percent])\n",
    "            gambling=\"/media/D/zephyr/functional_connectivity/HCP/s1200/percent_{}/GAMBLING\".format(percent_value[percent])\n",
    "            print('=' * 50)\n",
    "            dataset = MyDataset(data[test_index],emotion,gambling)\n",
    "            model.load_state_dict(torch.load('/media/D/zephyr/vit_155_155/other_baseline/path_save/2class_rondom_{}_{}_{}_new.pth'.\n",
    "                                            format(random_state_num,int(percent_value[percent]*100),k),map_location=torch.device('cpu')))\n",
    "            model=model.to(device)\n",
    "            model.eval()\n",
    "            attribution_generator = LRP(model)\n",
    "            test_data=data[test_index]\n",
    "            num_train = len(data[test_index])\n",
    "            print(num_train)\n",
    "            for cls in np.arange(2):\n",
    "                # output = torch.zeros((155,155))#fix\n",
    "                for ima_num in np.arange(num_train*cls,num_train*(cls+1)):  #num_train*cls,num_train*(cls+1)\n",
    "                    result_1,result_2 = generate_visualization(original_image = dataset[ima_num][0],class_index=dataset[ima_num][1].numpy())\n",
    "                    # output = output + result\n",
    "                    np.save('/media/D/zephyr/vit_155_155/other_baseline/vis/{}/{}_{}_edge_{}_2class_original'\n",
    "                            .format(int(percent_value[percent]*100),CLS2IDX[cls],test_data[ima_num%num_train],random_state_num),result_1)\n",
    "                    np.save('/media/D/zephyr/vit_155_155/other_baseline/vis/{}/{}_{}_node_{}_2class_original'\n",
    "                            .format(int(percent_value[percent]*100),CLS2IDX[cls],test_data[ima_num%num_train],random_state_num),result_2)\n",
    "        # for cls in np.arange(0,8):\n",
    "        #     output = torch.zeros((223,223))\n",
    "        #     for ima_num in np.arange(652*cls,652*(cls+1)):\n",
    "        #         result = generate_visualization(original_image = train_dataset[ima_num][0],class_index=train_dataset[ima_num][1].numpy())\n",
    "        #         output = output + result\n",
    "        #     np.savetxt('edge_random_30_{}_{}.txt'.format(k,CLS2IDX[cls]),output,'%.4f')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('zifanwang')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1b0e1c1f674c7a3f2024235257c833b5da488d07cf69737d343076bd9fe1bd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
