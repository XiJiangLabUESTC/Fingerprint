{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from baselines.ViT.ViT_LRP_copy import vit_base_patch16_224 as vit_LRP\n",
    "from baselines.ViT.ViT_explanation_generator import LRP\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, vit_data,emotion,gambling,language,motor,relational,social,wm):\n",
    "        self.emotion=[os.path.join(emotion,str(item)+'.mat') for item in vit_data]\n",
    "        self.gambling=[os.path.join(gambling,str(item)+'.mat') for item in vit_data]\n",
    "        self.language=[os.path.join(language,str(item)+'.mat') for item in vit_data]\n",
    "        self.motor=[os.path.join(motor,str(item)+'.mat') for item in vit_data]\n",
    "        self.relational=[os.path.join(relational,str(item)+'.mat') for item in vit_data]\n",
    "        self.social=[os.path.join(social,str(item)+'.mat') for item in vit_data]\n",
    "        self.wm=[os.path.join(wm,str(item)+'.mat') for item in vit_data]\n",
    "        self.data=self.emotion+self.gambling+self.language+self.motor+self.relational+self.social+self.wm\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        image=self.data[idx]\n",
    "        image=h5py.File(image,'r')\n",
    "        image = np.array(image['fc_matrix'])\n",
    "        image=torch.from_numpy(image).float()\n",
    "        if self.data[idx] in self.emotion:\n",
    "            label=torch.tensor(0)\n",
    "        elif self.data[idx] in self.gambling:\n",
    "            label=torch.tensor(1)\n",
    "        elif self.data[idx] in self.language:\n",
    "            label=torch.tensor(2)\n",
    "        elif self.data[idx] in self.motor:\n",
    "            label=torch.tensor(3)\n",
    "        elif self.data[idx] in self.relational:\n",
    "            label=torch.tensor(4)\n",
    "        elif self.data[idx] in self.social:\n",
    "            label=torch.tensor(5)\n",
    "        else:\n",
    "            label=torch.tensor(6)\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyDataset(Dataset):\n",
    "#     def __init__(self, vit_data,rest,task):\n",
    "#         self.rest=[os.path.join(rest,str(item)+'.mat') for item in vit_data]\n",
    "#         self.task=[os.path.join(task,str(item)+'.mat') for item in vit_data]\n",
    "#         self.data=self.rest+self.task\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "#     def __getitem__(self, idx):\n",
    "#         image=self.data[idx]\n",
    "#         image=h5py.File(image,'r')\n",
    "#         image = np.array(image['fc_matrix'])\n",
    "#         image=torch.from_numpy(image).float()\n",
    "#         if self.data[idx] in self.rest:\n",
    "#             label=torch.tensor(0)\n",
    "#         else:\n",
    "#             label=torch.tensor(1)\n",
    "#         return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualization(original_image, class_index=None):\n",
    "        transformer_attribution = attribution_generator.generate_LRP(original_image.unsqueeze(0).to(device), method=\"transformer_attribution_conn\", index=class_index).detach().cpu()\n",
    "        # transformer_attribution = ((transformer_attribution - transformer_attribution.min()) / (transformer_attribution.max() - transformer_attribution.min()))\n",
    "        transformer_attribution_edge = transformer_attribution.reshape(220,220)[1:,1:]\n",
    "        transformer_attribution_node = transformer_attribution.reshape(220,220)[0,1:]\n",
    "        diag = torch.diag(transformer_attribution_edge)\n",
    "        a_diag = torch.diag_embed(diag)\n",
    "        transformer_attribution_edge = transformer_attribution_edge - a_diag\n",
    "        # transformer_attribution_edge = ((transformer_attribution_edge - transformer_attribution_edge.min()) / (transformer_attribution_edge.max() - transformer_attribution_edge.min()))\n",
    "        # transformer_attribution_node = ((transformer_attribution_node - transformer_attribution_node.min()) / (transformer_attribution_node.max() - transformer_attribution_node.min()))\n",
    "        return transformer_attribution_edge,transformer_attribution_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start percent divide:1998 15\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:1998 20\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:1998 25\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:1998 30\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:1999 15\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:1999 20\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:1999 25\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:1999 30\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2000 15\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2000 20\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2000 25\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2000 30\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2001 15\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2001 20\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2001 25\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2001 30\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2002 15\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2002 20\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2002 25\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2002 30\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2003 15\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2003 20\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2003 25\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "start percent divide:2003 30\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "202\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n",
      "==================================================\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "model = vit_LRP(pretrained=False,num_classes=7,in_chans=1)\n",
    "model.patch_embed=torch.nn.Linear(219,model.pos_embed.shape[2])\n",
    "model.pos_embed=torch.nn.Parameter(torch.zeros(1, 219+1, model.pos_embed.shape[2]))\n",
    "CLS2IDX =  ['emotion','gambling','language','motor','relational','social','wm']\n",
    "for random_state_num in range(1998,2004):\n",
    "    data = np.arange(1,1008)\n",
    "    kf=KFold(n_splits=5,shuffle=True,random_state=random_state_num)\n",
    "    percent_value = [15,20,25,30]\n",
    "    for percent in range(4):\n",
    "        print('start percent divide:{} {}'.format(random_state_num,percent_value[percent]))\n",
    "        for k,(train_index, test_index) in list(enumerate(kf.split(data))):\n",
    "            emotion=\"/media/D/zephyr/functional_connectivity/HCP/Schaefer/Schaefer_7net/{}/EMOTION\".format(percent_value[percent])\n",
    "            gambling=\"/media/D/zephyr/functional_connectivity/HCP/Schaefer/Schaefer_7net/{}/GAMBLING\".format(percent_value[percent])\n",
    "            language=\"/media/D/zephyr/functional_connectivity/HCP/Schaefer/Schaefer_7net/{}/LANGUAGE\".format(percent_value[percent])\n",
    "            motor=\"/media/D/zephyr/functional_connectivity/HCP/Schaefer/Schaefer_7net/{}/MOTOR\".format(percent_value[percent])\n",
    "            relational=\"/media/D/zephyr/functional_connectivity/HCP/Schaefer/Schaefer_7net/{}/RELATIONAL\".format(percent_value[percent])\n",
    "            social=\"/media/D/zephyr/functional_connectivity/HCP/Schaefer/Schaefer_7net/{}/SOCIAL\".format(percent_value[percent])\n",
    "            wm=\"/media/D/zephyr/functional_connectivity/HCP/Schaefer/Schaefer_7net/{}/WM\".format(percent_value[percent])\n",
    "            print('=' * 50)\n",
    "            dataset=MyDataset(data[test_index],emotion,gambling,language,motor,relational,social,wm)\n",
    "            model.load_state_dict(torch.load('/media/D/zephyr/vit_155_155/other_map/aparc_path/Schaefer_rondom_{}_{}_{}_new.pth'.\n",
    "                                            format(random_state_num,percent_value[percent],k),map_location=torch.device('cpu')))\n",
    "            model=model.to(device)\n",
    "            model.eval()\n",
    "            attribution_generator = LRP(model)\n",
    "            test_data=data[test_index]\n",
    "            num_train = len(data[test_index])\n",
    "            print(num_train)\n",
    "            for cls in np.arange(7):\n",
    "                # output = torch.zeros((155,155))#fix\n",
    "                for ima_num in np.arange(num_train*cls,num_train*(cls+1)):  #num_train*cls,num_train*(cls+1)\n",
    "                    result_1,result_2 = generate_visualization(original_image = dataset[ima_num][0],class_index=dataset[ima_num][1].numpy())\n",
    "                    # output = output + result\n",
    "                    np.save('/media/D/zephyr/vit_155_155/other_map/aparc_vis/{}/{}/Schaefer_{}_edge_{}_7class_original'\n",
    "                            .format(percent_value[percent],CLS2IDX[cls],test_data[ima_num%num_train],random_state_num),result_1)\n",
    "                    np.save('/media/D/zephyr/vit_155_155/other_map/aparc_vis/{}/{}/Schaefer_{}_node_{}_7class_original'\n",
    "                            .format(percent_value[percent],CLS2IDX[cls],test_data[ima_num%num_train],random_state_num),result_2)\n",
    "        # for cls in np.arange(0,8):\n",
    "        #     output = torch.zeros((223,223))\n",
    "        #     for ima_num in np.arange(652*cls,652*(cls+1)):\n",
    "        #         result = generate_visualization(original_image = train_dataset[ima_num][0],class_index=train_dataset[ima_num][1].numpy())\n",
    "        #         output = output + result\n",
    "        #     np.savetxt('edge_random_30_{}_{}.txt'.format(k,CLS2IDX[cls]),output,'%.4f')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('zifanwang')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1b0e1c1f674c7a3f2024235257c833b5da488d07cf69737d343076bd9fe1bd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
